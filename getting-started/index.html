



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="A Material Design theme for MkDocs">
      
      
        <link rel="canonical" href="https://squidfunk.github.io/mkdocs-material/getting-started/">
      
      
        <meta name="author" content="Martin Donath">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>Decision  Tree - Miranda Damayanti</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
      <script src="../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#decision-tree" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://squidfunk.github.io/mkdocs-material/" title="Miranda Damayanti" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Miranda Damayanti
            </span>
            <span class="md-header-nav__topic">
              Decision  Tree
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/damayanti07/Decision-Tree" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MirandaDamayanti
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

<nav class="md-tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href=".." title="K-Nearest Neighbor" class="md-tabs__link md-tabs__link--active">
        K-Nearest Neighbor
      </a>
    
  </li>

      
        
      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://squidfunk.github.io/mkdocs-material/" title="Miranda Damayanti" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Miranda Damayanti
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/damayanti07/Decision-Tree" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    MirandaDamayanti
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="K-Nearest Neighbor" class="md-nav__link">
      K-Nearest Neighbor
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Decision  Tree
      </label>
    
    <a href="./" title="Decision Tree" class="md-nav__link md-nav__link--active">
      Decision  Tree
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#model-pohon-keputusan" title="Model Pohon Keputusan" class="md-nav__link">
    Model Pohon Keputusan
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#model-pohon-keputusan" title="Model Pohon Keputusan" class="md-nav__link">
    Model Pohon Keputusan
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="decision-tree">Decision  Tree<a class="headerlink" href="#decision-tree" title="Permanent link">&para;</a></h1>
<p>Pohon keputusan adalah gambaran skematik dari alternatif yang rersedia bagi pengambil keputusan dan kemungkinan hasilnya. Istilah pohon keputusan diambil dari bentuk diagramnya yang memiliki cabang dan ranting seperti halnya suatu pohon. Pohon Keputusan memiliki fungsi yang sama dengan tabel keputusan, namun biasanya lebih sesuai untuk ssituasi analisis yang memiliki keputusan berjenjang.</p>
<p>Pohon keputusan merupakan salah satu metode yang digunakan pada data  mining. Metode pohon keputusan mengubah fakta yang sangat besar menjadi pohon keputusan yang  merepresentasikan rule.  Pohon  keputusan  adalah  salah  satu  metode  klasifikasi yang paling populer karena mudah untuk diinterpretasikanoleh manusia. Konsep dari pohon  keputusan  adalah  mengubah  data  menjadi model pohon  keputusan(decision tree) dan aturan-aturan (rule).</p>
<p>Data  dalam  pohon  keputusan  biasanya  dinyatakan  dalam  bentuk  tabel  dengan atribut  dan record.  Atribut  menyatakan  suatu  parameter  yang  dibuat  sebagai  kriteria dalam  pembentukan tree.  Misalkan,untuk  menentukan bermain  tenis atau  tidak, kriteria  yang  diperhatikan  adalah  cuaca,  angin  dan  temperatur.  Salah  satu  atribut merupakan  atribut  yang  menyatakan  data  solusi  per-item  data  yang  disebut  dengan target atribut. Atribut memiliki nilai-nilai yang dinamakan dengan instance. Misalkan atribut cuaca mempunyai instances berupa cerah, berawan,dan hujan.</p>
<p>Pohon  keputusan  merupakan  himpunan  aturan  IF...THEN.  Setiap path dalam tree dihubungkan dengan sebuah aturan, dimana premis terdiri atas sekumpulan node-node yang  ditemui,  dan  kesimpulan  dari  aturan terdiri  atas  kelas  yang  terhubung  dengan leaf dari path.</p>
<p>Bagian awal dari pohon keputusan ini adalah titik akar (root), sedangkan setiap cabang  dari  pohon  keputusan  merupakan  pembagian  berdasarkan  hasil  ujidan  titik akhir (leaf) merupakan pembagian kelas yang dihasilkan. Pohon keputusan mempunyai tiga (3) tipe simpul, yaitu:</p>
<ol>
<li>Simpul akar(root): tidak memiliki cabang yang masuk dan memiliki cabang lebih dari  satu,  terkadang  tidak  memiliki  cabang  sama  sekali.  Simpul  ini  biasanya berupa atribut yang paling memiliki pengaruh terbesar pada suatu kelas tertentu.</li>
<li>Simpul internal(node): hanya  memiliki satu  cabang  yang  masukdan memiliki lebih dari satucabang yang keluar.</li>
<li>Simpul  daun(leaf): simpul  akhir yanghanya  memiliki satu  cabang  yang masukdan  tidak  memiliki  cabang  sama  sekali sekaligusmenandai  bahwa  simpul tersebut merupakan label kelas.</li>
</ol>
<p><strong>Manfaat Pohon Keputusan</strong></p>
<p>Pohon keputusan adalah salah satu metode klasifikasi yang paling populer karena mudah untuk diinterpretasi oleh manusia. Pohon keputusan adalah model prediksi menggunakan struktur pohon atau struktur berhirarki. Konsep dari pohon keputusan adalah mengubah data menjadi pohon keputusan dan aturan-aturan keputusan. Manfaat utama dari penggunaan pohon keputusan adalah kemampuannya untuk mem-<em>break down</em> proses pengambilan keputusan yang kompleks menjadi lebih simpel sehingga pengambil keputusan akan lebih menginterpretasikan solusi dari permasalahan. Pohon Keputusan juga berguna untuk mengeksplorasi data, menemukan hubungan tersembunyi
 antara sejumlah calon variabel input dengan sebuah variabel target. Pohon keputusan memadukan antara
 eksplorasi data dan pemodelan, sehingga  sangat bagus sebagai langkah awal dalam proses pemodelan bahkan ketika
 dijadikan sebagai model akhir dari beberapa teknik lain. Sering terjadi tawar menawar antara keakuratan
 model dengan transparansi model. Dalam beberapa aplikasi, akurasi dari sebuah klasifikasi atau prediksi adalah satu-satunya hal yang ditonjolkan, misalnya sebuah perusahaan <em>direct mail</em> membuat sebuah model yang akurat untuk
 memprediksi anggota mana yang berpotensi untuk merespon permintaan, tanpa memperhatikan bagaimana atau mengapa model tersebut bekerja.</p>
<p><strong>Kelebihan Pohon Keputusan</strong></p>
<p>Kelebihan dari metode pohon keputusan adalah:</p>
<p>§  Daerah pengambilan keputusan yang sebelumnya kompleks dan sangat global, dapat diubah menjadi lebih simpel dan spesifik.</p>
<p>§  Eliminasi perhitungan-perhitungan yang tidak diperlukan, karena ketika menggunakan metode pohon keputusan maka sample diuji hanya berdasarkan kriteria atau kelas tertentu.</p>
<p>§  Fleksibel untuk memilih fitur dari internal node yang berbeda, fitur yang terpilih akan membedakan suatu kriteria dibandingkan kriteria yang lain dalam node yang sama. Kefleksibelan metode pohon keputusan ini meningkatkan kualitas keputusan yang dihasilkan jika dibandingkan ketika menggunakan metode penghitungan satu tahap yang lebih konvensional</p>
<p>§  Dalam analisis multivariat, dengan kriteria dan kelas yang jumlahnya sangat banyak, seorang penguji biasanya perlu untuk mengestimasikan baik itu distribusi dimensi tinggi ataupun parameter tertentu dari distribusi kelas tersebut. Metode pohon keputusan dapat menghindari munculnya permasalahan ini dengan menggunakan criteria yang jumlahnya lebih sedikit pada setiap node internal tanpa banyak mengurangi kualitas keputusan yang dihasilkan.</p>
<p><strong>Kekurangan Pohon Keputusan</strong></p>
<p>§  Terjadi overlap terutama ketika kelas-kelas dan criteria yang digunakan jumlahnya sangat banyak. Hal tersebut juga dapat menyebabkan meningkatnya waktu pengambilan keputusan dan jumlah memori yang diperlukan.</p>
<p>§  Pengakumulasian jumlah eror dari setiap tingkat dalam sebuah pohon keputusan yang besar.</p>
<p>§  Kesulitan dalam mendesain pohon keputusan yang optimal.</p>
<p>§  Hasil kualitas keputusan yang didapatkan dari metode pohon keputusan sangat tergantung pada bagaimana pohon tersebut didesain.</p>
<h6 id="model-pohon-keputusan"><strong>Model Pohon Keputusan</strong><a class="headerlink" href="#model-pohon-keputusan" title="Permanent link">&para;</a></h6>
<p>Pohon keputusan adalah model prediksi menggunakan struktur pohon atau struktur berhirarki. Contoh dari pohon keputusan dapat dilihat di Gambar berikut ini.</p>
<p>Disini setiap percabangan menyatakan kondisi yang harus dipenuhi dan tiap ujung pohon menyatakan kelas data. Contoh di Gambar 1 adalah identifikasi pembeli komputer,dari pohon keputusan tersebut diketahui bahwa salah satu kelompok yang potensial membeli komputer adalah orang yang berusia di bawah 30 tahun dan juga pelajar. Setelah sebuah pohon keputusan dibangun maka dapat digunakan untuk mengklasifikasikan <em>record</em> yang belum ada kelasnya. Dimulai dari <em>node root</em>, menggunakan tes terhadap atribut dari <em>record</em> yang belum ada kelasnya tersebut lalu mengikuti cabang yang sesuai dengan hasil dari tes tersebut, yang akan membawa kepada <em>internal node</em> (<em>node</em> yang memiliki satu cabang masuk dan dua atau lebih cabang yang keluar), dengan cara harus melakukan tes lagi terhadap atribut atau <em>node</em> daun. <em>Record</em> yang kelasnya tidak diketahui kemudian diberikan kelas yang sesuai dengan kelas yang ada pada <em>node</em> daun. Pada pohon keputusan setiap simpul daun menandai label kelas. Proses dalam pohon keputusan yaitu mengubah bentuk data (tabel) menjadi model pohon (<em>tree</em>) kemudian mengubah model pohon tersebut menjadi aturan (<em>rule</em>).</p>
<p>Referensi</p>
<p><a href="https://myforcedblogs.blogspot.com/2017/01/pohon-keputusan.html">https://myforcedblogs.blogspot.com/2017/01/pohon-keputusan.html</a></p>
<p><a href="https://fairuzelsaid.wordpress.com/2009/11/24/data-mining-konsep-pohon-keputusan/">https://fairuzelsaid.wordpress.com/2009/11/24/data-mining-konsep-pohon-keputusan/</a></p>
<h1 id="algoritma-c-45"><strong>Algoritma C 4.5</strong><a class="headerlink" href="#algoritma-c-45" title="Permanent link">&para;</a></h1>
<h2 id="a-pengertian">A. Pengertian<a class="headerlink" href="#a-pengertian" title="Permanent link">&para;</a></h2>
<p>Algoritma C4.5 adalah algoritma yang sering digunakan dalam clasifikasi, berasal dari algoritma membagi dan menaklukkan sederhana untuk menghasilkan pohon keputusan.</p>
<p>Banyak algoritma yang dapat dipakai dalam pembentukan pohon keputusan, antara lain : ID3, CART, dan C4.5. Algoritma C4.5 merupakan pengembangan dari algoritma ID3, Proses pada pohon keputusan adalah mengubah bentuk data (tabel) menjadi model pohon, mengubah model pohon menjadi rule, dan menyederhanakan rule.</p>
<p>Secara umum algoritma C4.5 untuk membangun pohon keputusan adalah sebagai berikut :</p>
<p>·         Pilih atribut sebagai akar.</p>
<p>·         Buat cabang untuk tiap-tiap nilai.</p>
<p>·         Bagi kasus dalam cabang.</p>
<p>·         Ulangi proses untuk setiap cabang sampai semua kasus pada cabang memiliki kelas yang sama.</p>
<h2 id="b-kelebihan">B. Kelebihan<a class="headerlink" href="#b-kelebihan" title="Permanent link">&para;</a></h2>
<h4 id="mampu-menangani-atribut-dengan-tipe-diskrit-atau-kontinu"><strong>Mampu Menangani Atribut dengan Tipe Diskrit atau Kontinu</strong><a class="headerlink" href="#mampu-menangani-atribut-dengan-tipe-diskrit-atau-kontinu" title="Permanent link">&para;</a></h4>
<p>Pemilihan atribut pada algoritma induksi decision tree menggunakan ukuran berdasarkan entropy yang dikenal dengan information gain sebagai sebuah heuristic untuk memilih atribut yang merupakan bagian terbaik dari contoh ke dalam kelas. Semua atribut adalah bersifat kategori yang bernilai diskrit. Atribut dengan nilai <em>continuous</em> harus didiskritkan.</p>
<h4 id="mampu-menangani-atribut-yang-kosong-missing-value"><strong>Mampu Menangani Atribut yang Kosong (Missing Value)</strong><a class="headerlink" href="#mampu-menangani-atribut-yang-kosong-missing-value" title="Permanent link">&para;</a></h4>
<p>Cara paling mudah dalam pengisian atribut kosong adalah dengan memberikan nilai berdasar nilai yang paling banyak atau dominan dalam atribut tersebut</p>
<p>Pada saat pembangunan pohon keputusan, banyaknya cabang mungkin mencerminkan adanya <em>noise</em> atau <em>outlier</em> pada training data. Pemangkasan pohon dapat dilakukan untuk mengenali dan menghapus cabang-cabang tersebut. Pohon yang dipangkas akan menjadi lebih kecil dan lebih mudah dipahami. Pohon semacam itu biasanya juga menjadi lebih cepat dan lebih baik dalam melakukan klasifikasi.</p>
<p>Ada dua metode dalam melakukan pemangkasan dalam pohon keputusan, yaitu:
 <strong>a. Prepruning</strong>, yaitu menghentikan pembangunan suatu subtree lebih awal, yaitu dengan memutuskan untuk tidak lebih jauh mempartisi data training. Pada pendekatan prepruning, sebuah pohon dipangkas dengan cara menghentikan pembangunannya jika partisi yang akan dibuat dianggap tidak signifikan. Untuk mengetahui nilai parameter apakah akan dilakukan expanding atau pruning dapat menggunakan metode <em>chi-squared</em>.</p>
<p><strong>b. Postpruning</strong>, yaitu menyederhanakan pohon dengan cara membuang beberapa cabang subtree setelah pohon selesai dibangun. Metode postpruning ini merupakan metode standard untuk algoritma C4.5.</p>
<h4 id="reduced-error-pruning"><strong>Reduced Error Pruning</strong><a class="headerlink" href="#reduced-error-pruning" title="Permanent link">&para;</a></h4>
<p>merupakan salah satu algoritma postpruning. Algoritma ini membagi data menjadi dua, yaitu training data dan test data. Training data adalah data yang digunakan untuk membentuk pohon keputusan, sedangkan test data digunakan untuk menghitung nilai error rate pada pohon setelah dipangkas.</p>
<p>keterangan:
 r = nilai perbandingan error rate 
 n = total sample
 z = Φ-1©</p>
<h4 id="entropy-information-gain-gain-ration">**Entropy, Information Gain &amp; Gain Ratio**n<a class="headerlink" href="#entropy-information-gain-gain-ration" title="Permanent link">&para;</a></h4>
<p>Pemilihan atribut yang baik adalah atribut yang memungkinkan untuk mendapatkan decision tree yang paling kecil ukurannya. Atau atribut yang bisa memisahkan obyek menurut kelasnya. Secara heuristik atribut yang dipilih adalah atribut yang menghasilkan simpul yang paling ”purest” (paling bersih). Ukuran purity dinyatakan dengan tingkat impurity, dan untuk menghitungnya, dapat dilakukan dengan menggunakan konsep Entropy, Entropy menyatakan impurity suatu kumpulan objek.</p>
<p>Atribut dengan nilai Gain Ratio tertinggi dipilih sebagai atribut test untuk simpul. Dengan gain adalah information gain.</p>
<p>Dimana:</p>
<p>S = ruang (data) sample yang digunakan untuk training.</p>
<p>A = atribut.</p>
<p>Si = jumlah sample untuk atribut i </p>
<h1 id="dimana-xi-menyatakan-sub-himpunan-ke-i-pada-sampel-x">dimana <em>Xi</em> menyatakan sub himpunan ke-i pada sampel <em>X</em>.<a class="headerlink" href="#dimana-xi-menyatakan-sub-himpunan-ke-i-pada-sampel-x" title="Permanent link">&para;</a></h1>
<p>Dimana:</p>
<p>S = ruang (data) sample yang digunakan untuk training.</p>
<p>A = atribut.</p>
<p>|Si| = jumlah sample untuk nilai V.</p>
<p>|S| = jumlah seluruh sample data.</p>
<p>Entropi(Si) = entropy untuk sample-sample yang memiliki nilai <em>i</em></p>
<p>Referensi:</p>
<p><a href="https://informatikalogi.com/algoritma-c4-5/">https://informatikalogi.com/algoritma-c4-5/</a></p>
<p><a href="https://www.ilmuskripsi.com/2016/07/algoritma-c45.html">https://www.ilmuskripsi.com/2016/07/algoritma-c45.html</a></p>
<p><a href="https://medium.com/machine-learning-101/chapter-3-decision-trees-theory-e7398adac567">https://medium.com/machine-learning-101/chapter-3-decision-trees-theory-e7398adac567</a></p>
<h1 id="implementasi">implementasi<a class="headerlink" href="#implementasi" title="Permanent link">&para;</a></h1>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.externals.six</span> <span class="kn">import</span> <span class="n">StringIO</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>
<span class="kn">import</span> <span class="nn">pydotplus</span>
</pre></div>

<p>load data</p>
<div class="codehilite"><pre><span></span><span class="n">col_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;pregnant&#39;</span><span class="p">,</span> <span class="s1">&#39;glucose&#39;</span><span class="p">,</span> <span class="s1">&#39;bp&#39;</span><span class="p">,</span> <span class="s1">&#39;skin&#39;</span><span class="p">,</span> <span class="s1">&#39;insulin&#39;</span><span class="p">,</span> <span class="s1">&#39;bmi&#39;</span><span class="p">,</span> <span class="s1">&#39;pedigree&#39;</span><span class="p">,</span> <span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">]</span>
<span class="c1"># load dataset</span>
<span class="n">pima</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;diabetes1,csv&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">col_names</span><span class="p">)</span>
</pre></div>

<p>output:</p>
<div class="codehilite"><pre><span></span><span class="n">pregnant</span>  <span class="n">glucose</span>  <span class="n">bp</span>  <span class="n">skin</span>  <span class="n">insulin</span>   <span class="n">bmi</span>  <span class="n">pedigree</span>  <span class="n">age</span>  <span class="n">label</span>
<span class="mi">0</span>         <span class="mi">6</span>      <span class="mi">148</span>  <span class="mi">72</span>    <span class="mi">35</span>        <span class="mi">0</span>  <span class="mf">33.6</span>     <span class="mf">0.627</span>   <span class="mi">50</span>      <span class="mi">1</span>
<span class="mi">1</span>         <span class="mi">1</span>       <span class="mi">85</span>  <span class="mi">66</span>    <span class="mi">29</span>        <span class="mi">0</span>  <span class="mf">26.6</span>     <span class="mf">0.351</span>   <span class="mi">31</span>      <span class="mi">0</span>
<span class="mi">2</span>         <span class="mi">8</span>      <span class="mi">183</span>  <span class="mi">64</span>     <span class="mi">0</span>        <span class="mi">0</span>  <span class="mf">23.3</span>     <span class="mf">0.672</span>   <span class="mi">32</span>      <span class="mi">1</span>
<span class="mi">3</span>         <span class="mi">1</span>       <span class="mi">89</span>  <span class="mi">66</span>    <span class="mi">23</span>       <span class="mi">94</span>  <span class="mf">28.1</span>     <span class="mf">0.167</span>   <span class="mi">21</span>      <span class="mi">0</span>
<span class="mi">4</span>         <span class="mi">0</span>      <span class="mi">137</span>  <span class="mi">40</span>    <span class="mi">35</span>      <span class="mi">168</span>  <span class="mf">43.1</span>     <span class="mf">2.288</span>   <span class="mi">33</span>      <span class="mi">1</span>
</pre></div>

<p>seleksi fitur</p>
<p>Dalam step ini, perlu pembagian fitur. Untuk variabel X digunakan untuk fitur dan variabel Y digunakan untuk target.</p>
<div class="codehilite"><pre><span></span>feature_cols = [&#39;pregnant&#39;, &#39;insulin&#39;, &#39;bmi&#39;, &#39;age&#39;,&#39;glucose&#39;,&#39;bp&#39;,&#39;pedigree&#39;]
X = pima[feature_cols] # fitur
y = pima.label # target
</pre></div>

<p>split data</p>
<p>Selanjutnya split data menjadi 2 untuk data test dan data train</p>
<div class="codehilite"><pre><span></span><span class="c1">#split data : 30% data test, 70% data train</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

<p>Membuat model pohon keputusan </p>
<div class="codehilite"><pre><span></span> <span class="n">untuk</span> <span class="n">klasifikasi</span> <span class="n">objek</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;entropy&quot;</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># untuk train pohon keputusan</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1">#untuk prediksi data yg diuji</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1">#menampilkan akurasi</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>  
</pre></div>

<p>output  Akurasi</p>
<div class="codehilite"><pre><span></span><span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.7705627705627706</span>
</pre></div>

<p>visualisasi pohon keputusan</p>
<p>Visualisasi data menggunakan code berikut</p>
<div class="codehilite"><pre><span></span><span class="n">dot_data</span> <span class="o">=</span> <span class="n">StringIO</span><span class="p">()</span>
<span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="n">dot_data</span><span class="p">,</span>  
                <span class="n">filled</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                <span class="n">special_characters</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">feature_names</span> <span class="o">=</span> <span class="n">feature_cols</span><span class="p">,</span><span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;0&#39;</span><span class="p">,</span><span class="s1">&#39;1&#39;</span><span class="p">])</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">pydotplus</span><span class="o">.</span><span class="n">graph_from_dot_data</span><span class="p">(</span><span class="n">dot_data</span><span class="o">.</span><span class="n">getvalue</span><span class="p">())</span>  
<span class="n">graph</span><span class="o">.</span><span class="n">write_png</span><span class="p">(</span><span class="s1">&#39;diabetes.png&#39;</span><span class="p">)</span>
<span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">create_png</span><span class="p">())</span>
</pre></div>

<p>Referensi:</p>
<p><a href="https://medium.com/machine-learning-101/chapter-3-decision-trees-theory-e7398adac567">https://medium.com/machine-learning-101/chapter-3-decision-trees-theory-e7398adac567</a></p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href=".." title="K-Nearest Neighbor" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                K-Nearest Neighbor
              </span>
            </div>
          </a>
        
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2016 - 2019 Martin Donath
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="http://struct.cc" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="https://github.com/squidfunk" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://twitter.com/squidfunk" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://linkedin.com/in/squidfunk" class="md-footer-social__link fa fa-linkedin"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.8c0d971c.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
  </body>
</html>